{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaec9f2b-1c93-48d4-bb92-9de9d8e811d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "## This notebook includes simulation and experimental data\n",
    "## in a database using PyMongo\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from botorch.models.transforms.input import AffineInputTransform\n",
    "from botorch.models import MultiTaskGP, SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "from lume_model.models import TorchModel\n",
    "from lume_model.variables import ScalarVariable, DistributionVariable\n",
    "from lume_model.models.gp_model import GPModel\n",
    "import sys\n",
    "import gpytorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2720f3-c7ec-4185-9c52-b04d29f3bace",
   "metadata": {},
   "source": [
    "<h1>Setup</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0323fbfe-45df-4975-a9a7-3dcf04f549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select experimental setup for which we are training a model\n",
    "setup = \"ip2\"\n",
    "\n",
    "# Open credential file for database\n",
    "with open(os.path.join(os.getenv('HOME'), 'db.profile')) as f:\n",
    "    db_profile = f.read()\n",
    "\n",
    "# Connect to the MongoDB database with read-only access\n",
    "db = pymongo.MongoClient(\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    username=\"bella_sf_ro\",\n",
    "    password=re.findall('SF_DB_READONLY_PASSWORD=(.+)', db_profile)[0],\n",
    "    authSource=\"bella_sf\")[\"bella_sf\"]\n",
    "# Extract data from the database as pandas dataframe\n",
    "collection=db[setup]\n",
    "df_train = pd.DataFrame( list(collection.find()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e28501-8899-4666-bcb6-8e1ff6804a71",
   "metadata": {},
   "source": [
    "<h1>Prepare Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc99f0e0-d996-4c1d-b92a-ff57fa4ff041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of inputs and outputs for this setup\n",
    "path_to_IFE_sf_src = \"/global/cfs/cdirs/m558/superfacility/\"\n",
    "path_to_IFE_ml = \"/global/cfs/cdirs/m558/superfacility/model_training/src/\"\n",
    "sys.path.append(path_to_IFE_ml)\n",
    "\n",
    "with open(\"/global/cfs/cdirs/m558/superfacility/model_training/src/variables.yml\") as f:\n",
    "    yaml_dict = yaml.safe_load( f.read() )\n",
    "input_variables = yaml_dict[setup][\"input_variables\"]\n",
    "input_names = [ v['name'] for v in input_variables.values() ] \n",
    "output_variables = yaml_dict[setup][\"output_variables\"]\n",
    "output_names = [ v['name'] for v in output_variables.values() ]\n",
    "\n",
    "#Normalize with Affine Input Transformer\n",
    "# Define the input and output normalizations\n",
    "X = torch.tensor( df_train[ input_names ].values, dtype=torch.float )\n",
    "input_transform = AffineInputTransform( \n",
    "    len(input_names), \n",
    "    coefficient=X.std(axis=0), \n",
    "    offset=X.mean(axis=0)\n",
    ")\n",
    "y = torch.tensor( df_train[ output_names ].values, dtype=torch.float )\n",
    "output_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=y.std(axis=0),\n",
    "    offset=y.mean(axis=0)\n",
    ")\n",
    "\n",
    "# Apply normalization to the data set\n",
    "norm_df = df_train.copy()\n",
    "norm_df[input_names] = input_transform( torch.tensor( df_train[input_names].values ) )\n",
    "norm_df[output_names] = output_transform( torch.tensor( df_train[output_names].values ) )\n",
    "\n",
    "norm_expt_inputs_training = torch.tensor( norm_df[norm_df.experiment_flag==1][input_names].values, dtype=torch.float)\n",
    "norm_expt_outputs_training = torch.tensor( norm_df[norm_df.experiment_flag==1][output_names].values, dtype=torch.float)\n",
    "norm_sim_inputs_training = torch.tensor( norm_df[norm_df.experiment_flag==0][input_names].values, dtype=torch.float)\n",
    "norm_sim_outputs_training = torch.tensor( norm_df[norm_df.experiment_flag==0][output_names].values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc7d4d-e6d8-4fac-9f30-6649777a408a",
   "metadata": {},
   "source": [
    "<h1>Create and train GP model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9d8812d-7045-4db1-ad95-e1198953ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:  tensor(0.3518, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must train on the training inputs!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m     21\u001b[39m mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Fix mismatch in name between the config file and the expected lume-model format\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m input_variables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/fit.py:115\u001b[39m, in \u001b[36mfit_gpytorch_mll\u001b[39m\u001b[34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[32m    113\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m\"\u001b[39m] = optimizer\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFitGPyTorchMLL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/utils/dispatcher.py:95\u001b[39m, in \u001b[36mDispatcher.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m func = \u001b[38;5;28mself\u001b[39m.\u001b[34m__getitem__\u001b[39m(types=types)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[32m     98\u001b[39m     funcs = \u001b[38;5;28mself\u001b[39m.dispatch_iter(*types)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/fit.py:215\u001b[39m, in \u001b[36m_fit_fallback\u001b[39m\u001b[34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, pick_best_of_all_attempts, warning_handler, caught_exception_types, **ignore)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list:\n\u001b[32m    214\u001b[39m     simplefilter(\u001b[33m\"\u001b[39m\u001b[33malways\u001b[39m\u001b[33m\"\u001b[39m, category=OptimizationWarning)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     result = \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# Resolve warnings and determine whether or not to retry\u001b[39;00m\n\u001b[32m    218\u001b[39m success = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/fit.py:94\u001b[39m, in \u001b[36mfit_gpytorch_mll_scipy\u001b[39m\u001b[34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     closure = partial(closure, **closure_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m result = \u001b[43mscipy_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.status != OptimizationStatus.SUCCESS:\n\u001b[32m    104\u001b[39m     warn(\n\u001b[32m    105\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`scipy_minimize` terminated with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, displaying\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         OptimizationWarning,\n\u001b[32m    108\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/core.py:114\u001b[39m, in \u001b[36mscipy_minimize\u001b[39m\u001b[34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[39m\n\u001b[32m    106\u001b[39m         result = OptimizationResult(\n\u001b[32m    107\u001b[39m             step=\u001b[38;5;28mnext\u001b[39m(call_counter),\n\u001b[32m    108\u001b[39m             fval=\u001b[38;5;28mfloat\u001b[39m(wrapped_closure(x)[\u001b[32m0\u001b[39m]),\n\u001b[32m    109\u001b[39m             status=OptimizationStatus.RUNNING,\n\u001b[32m    110\u001b[39m             runtime=monotonic() - start_time,\n\u001b[32m    111\u001b[39m         )\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(parameters, result)  \u001b[38;5;66;03m# pyre-ignore [29]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m raw = \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Post-processing and outcome handling\u001b[39;00m\n\u001b[32m    126\u001b[39m wrapped_closure.state = asarray(raw.x)  \u001b[38;5;66;03m# set parameter state to optimal values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/utils/timeout.py:86\u001b[39m, in \u001b[36mminimize_with_timeout\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# To prevent slowdowns after scipy 1.15.\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/22438.\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits=\u001b[32m1\u001b[39m, user_api=\u001b[33m\"\u001b[39m\u001b[33mblas\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    101\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.runtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_minimize.py:738\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    735\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    736\u001b[39m                              **options)\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    741\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    742\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_lbfgsb_py.py:386\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    383\u001b[39m     x0 = np.clip(x0, bounds[\u001b[32m0\u001b[39m], bounds[\u001b[32m1\u001b[39m])\n\u001b[32m    385\u001b[39m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m sf = \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m func_and_grad = sf.fun_and_grad\n\u001b[32m    392\u001b[39m nbd = zeros(n, np.int32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_optimize.py:291\u001b[39m, in \u001b[36m_prepare_scalar_function\u001b[39m\u001b[34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[39m\n\u001b[32m    287\u001b[39m     bounds = (-np.inf, np.inf)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m sf = \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:223\u001b[39m, in \u001b[36mScalarFunction.__init__\u001b[39m\u001b[34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[39m\n\u001b[32m    220\u001b[39m     finite_diff_options[\u001b[33m\"\u001b[39m\u001b[33mas_linear_operator\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Initial function evaluation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28mself\u001b[39m._wrapped_grad, \u001b[38;5;28mself\u001b[39m._ngev = _wrapper_grad(\n\u001b[32m    227\u001b[39m     grad,\n\u001b[32m    228\u001b[39m     fun=\u001b[38;5;28mself\u001b[39m._wrapped_fun,\n\u001b[32m    229\u001b[39m     args=args,\n\u001b[32m    230\u001b[39m     finite_diff_options=finite_diff_options\n\u001b[32m    231\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n\u001b[32m    297\u001b[39m             \u001b[38;5;28mself\u001b[39m._lowest_x = \u001b[38;5;28mself\u001b[39m.x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[39m, in \u001b[36m_wrapper_fun.<locals>.wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     17\u001b[39m ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/closures/core.py:159\u001b[39m, in \u001b[36mNdarrayOptimizationClosure.__call__\u001b[39m\u001b[34m(self, state, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m         index += size\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     value, grads = \u001b[43m_handle_numerical_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value, grads\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/utils/common.py:34\u001b[39m, in \u001b[36m_handle_numerical_errors\u001b[39m\u001b[34m(error, x, dtype)\u001b[39m\n\u001b[32m     32\u001b[39m     _dtype = x.dtype \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.full((), \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m, dtype=_dtype), np.full_like(x, \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m, dtype=_dtype)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/closures/core.py:149\u001b[39m, in \u001b[36mNdarrayOptimizationClosure.__call__\u001b[39m\u001b[34m(self, state, **kwargs)\u001b[39m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.state = state\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     value_tensor, grad_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     value = \u001b[38;5;28mself\u001b[39m.as_array(value_tensor)\n\u001b[32m    151\u001b[39m     grads = \u001b[38;5;28mself\u001b[39m._get_gradient_ndarray(fill_value=\u001b[38;5;28mself\u001b[39m.fill_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/closures/core.py:68\u001b[39m, in \u001b[36mForwardBackwardClosure.__call__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mtuple\u001b[39m[Tensor, \u001b[38;5;28mtuple\u001b[39m[Tensor | \u001b[38;5;28;01mNone\u001b[39;00m, ...]]:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.context_manager():\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         value = values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reducer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reducer(values)\n\u001b[32m     70\u001b[39m         \u001b[38;5;28mself\u001b[39m.backward(value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/botorch/optim/closures/model_closures.py:178\u001b[39m, in \u001b[36m_get_loss_closure_exact_internal.<locals>.closure\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m model = mll.model\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# The inputs will get transformed in forward here.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m model_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m log_likelihood = mll(\n\u001b[32m    180\u001b[39m     model_output,\n\u001b[32m    181\u001b[39m     model.train_targets,\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m     **kwargs,\n\u001b[32m    187\u001b[39m )\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m -log_likelihood\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/gpytorch/models/exact_gp.py:279\u001b[39m, in \u001b[36mExactGP.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m settings.debug.on():\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    277\u001b[39m         torch.equal(train_input, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m train_input, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m length_safe_zip(train_inputs, inputs)\n\u001b[32m    278\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must train on the training inputs!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m res = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*inputs, **kwargs)\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[31mRuntimeError\u001b[39m: You must train on the training inputs!"
     ]
    }
   ],
   "source": [
    "if setup != 'acave':\n",
    "    gp_model = MultiTaskGP(\n",
    "        torch.tensor( norm_df[['experiment_flag']+input_names].values ),\n",
    "        torch.tensor( norm_df[output_names].values ),\n",
    "        task_feature=0,\n",
    "        covar_module=ScaleKernel(MaternKernel(nu=1.5)),\n",
    "        outcome_transform=None,\n",
    "    )\n",
    "    cov = gp_model.task_covar_module._eval_covar_matrix()\n",
    "    print( 'Correlation: ', cov[1,0]/torch.sqrt(cov[0,0]*cov[1,1]).item() )\n",
    "\n",
    "else:\n",
    "    gp_model = SingleTaskGP(\n",
    "        torch.tensor(norm_df[input_names].values, dtype=torch.float64),\n",
    "        torch.tensor(norm_df[output_names].values, dtype=torch.float64),\n",
    "        covar_module=ScaleKernel(MaternKernel(nu=1.5)),\n",
    "        outcome_transform=None,\n",
    "    )\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Fix mismatch in name between the config file and the expected lume-model format\n",
    "for k in input_variables:\n",
    "    print(input_variables[k])\n",
    "    input_variables[k]['default_value'] = input_variables[k]['default']\n",
    "    del input_variables[k]['default']  \n",
    "\n",
    "input_variables = [ ScalarVariable(**input_variables[k]) for k in input_variables.keys() ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e31d2-c621-46b1-8774-09b64a1a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'/global/homes/e/erod/2024_IFE-superfacility/ml/NN_training/saved_models/GP/{setup}'\n",
    "if setup != 'acave':\n",
    "    output_variables = [\n",
    "        DistributionVariable(name=f\"{name}_{suffix}\", distribution_type=\"MultiVariateNormal\")\n",
    "        for name in output_names\n",
    "        for suffix in [\"sim_task\", \"exp_task\"]\n",
    "    ]\n",
    "else:\n",
    "    output_variables = [\n",
    "        DistributionVariable(name=f\"{name}_{suffix}\", distribution_type=\"MultiVariateNormal\")\n",
    "        for name in output_names\n",
    "        for suffix in [\"sim_task\"]\n",
    "    ]\n",
    "\n",
    "model = GPModel(\n",
    "    model=gp_model, \n",
    "    input_variables=input_variables_ordered,\n",
    "    output_variables=output_variables,\n",
    "    input_transformers=[input_transform],\n",
    "    output_transformers=[output_transform],\n",
    ")\n",
    "\n",
    "model.dump( file=os.path.join(save_path, setup+'GP.yml'),     \n",
    "save_models=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34a115-c193-49af-8520-f662d14d8280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfapi",
   "language": "python",
   "name": "sfapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
