{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaec9f2b-1c93-48d4-bb92-9de9d8e811d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "## This notebook includes simulation and experimental data\n",
    "## in a database using PyMongo\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from botorch.models.transforms.input import AffineInputTransform\n",
    "from botorch.models import MultiTaskGP, SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "from lume_model.models import TorchModel\n",
    "from lume_model.variables import ScalarVariable, DistributionVariable\n",
    "from lume_model.models.gp_model import GPModel\n",
    "import sys\n",
    "import gpytorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2720f3-c7ec-4185-9c52-b04d29f3bace",
   "metadata": {},
   "source": [
    "<h1>Setup</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0323fbfe-45df-4975-a9a7-3dcf04f549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select experimental setup for which we are training a model\n",
    "setup = \"ip2\"\n",
    "\n",
    "# Open credential file for database\n",
    "with open(os.path.join(os.getenv('HOME'), 'db.profile')) as f:\n",
    "    db_profile = f.read()\n",
    "\n",
    "# Connect to the MongoDB database with read-only access\n",
    "db = pymongo.MongoClient(\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    username=\"bella_sf_ro\",\n",
    "    password=re.findall('SF_DB_READONLY_PASSWORD=(.+)', db_profile)[0],\n",
    "    authSource=\"bella_sf\")[\"bella_sf\"]\n",
    "# Extract data from the database as pandas dataframe\n",
    "collection=db[setup]\n",
    "df_train = pd.DataFrame( list(collection.find()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e28501-8899-4666-bcb6-8e1ff6804a71",
   "metadata": {},
   "source": [
    "<h1>Prepare Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc99f0e0-d996-4c1d-b92a-ff57fa4ff041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of inputs and outputs for this setup\n",
    "path_to_IFE_sf_src = \"/global/cfs/cdirs/m558/superfacility/\"\n",
    "path_to_IFE_ml = \"/global/cfs/cdirs/m558/superfacility/model_training/src/\"\n",
    "sys.path.append(path_to_IFE_ml)\n",
    "\n",
    "with open(\"/global/cfs/cdirs/m558/superfacility/model_training/src/variables.yml\") as f:\n",
    "    yaml_dict = yaml.safe_load( f.read() )\n",
    "input_variables = yaml_dict[setup][\"input_variables\"]\n",
    "input_names = [ v['name'] for v in input_variables.values() ] \n",
    "output_variables = yaml_dict[setup][\"output_variables\"]\n",
    "output_names = [ v['name'] for v in output_variables.values() ]\n",
    "\n",
    "#Normalize with Affine Input Transformer\n",
    "# Define the input and output normalizations\n",
    "X = torch.tensor( df_train[ input_names ].values, dtype=torch.float )\n",
    "input_transform = AffineInputTransform( \n",
    "    len(input_names), \n",
    "    coefficient=X.std(axis=0), \n",
    "    offset=X.mean(axis=0)\n",
    ")\n",
    "y = torch.tensor( df_train[ output_names ].values, dtype=torch.float )\n",
    "output_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=y.std(axis=0),\n",
    "    offset=y.mean(axis=0)\n",
    ")\n",
    "\n",
    "# Apply normalization to the data set\n",
    "norm_df = df_train.copy()\n",
    "norm_df[input_names] = input_transform( torch.tensor( df_train[input_names].values ) )\n",
    "norm_df[output_names] = output_transform( torch.tensor( df_train[output_names].values ) )\n",
    "\n",
    "norm_expt_inputs_training = torch.tensor( norm_df[norm_df.experiment_flag==1][input_names].values, dtype=torch.float)\n",
    "norm_expt_outputs_training = torch.tensor( norm_df[norm_df.experiment_flag==1][output_names].values, dtype=torch.float)\n",
    "norm_sim_inputs_training = torch.tensor( norm_df[norm_df.experiment_flag==0][input_names].values, dtype=torch.float)\n",
    "norm_sim_outputs_training = torch.tensor( norm_df[norm_df.experiment_flag==0][output_names].values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc7d4d-e6d8-4fac-9f30-6649777a408a",
   "metadata": {},
   "source": [
    "<h1>Create and train GP model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9d8812d-7045-4db1-ad95-e1198953ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:  tensor(-0.2762, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'ndimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m     21\u001b[39m mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m _ = \u001b[43mgp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexperiment_flag\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m+\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m fit_gpytorch_mll(mll)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Fix mismatch in name between the config file and the expected lume-model format\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sfapi/lib/python3.13/site-packages/gpytorch/models/exact_gp.py:266\u001b[39m, in \u001b[36mExactGP.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    265\u001b[39m     train_inputs = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_inputs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     inputs = [i.unsqueeze(-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndimension\u001b[49m() == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# Training mode: optimizing\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'ndimension'"
     ]
    }
   ],
   "source": [
    "if setup != 'acave':\n",
    "    gp_model = MultiTaskGP(\n",
    "        torch.tensor( norm_df[['experiment_flag']+input_names].values ),\n",
    "        torch.tensor( norm_df[output_names].values ),\n",
    "        task_feature=0,\n",
    "        covar_module=ScaleKernel(MaternKernel(nu=1.5)),\n",
    "        outcome_transform=None,\n",
    "    )\n",
    "    cov = gp_model.task_covar_module._eval_covar_matrix()\n",
    "    print( 'Correlation: ', cov[1,0]/torch.sqrt(cov[0,0]*cov[1,1]).item() )\n",
    "\n",
    "else:\n",
    "    gp_model = SingleTaskGP(\n",
    "        torch.tensor(norm_df[input_names].values, dtype=torch.float64),\n",
    "        torch.tensor(norm_df[output_names].values, dtype=torch.float64),\n",
    "        covar_module=ScaleKernel(MaternKernel(nu=1.5)),\n",
    "        outcome_transform=None,\n",
    "    )\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "_ = gp_model(norm_df[['experiment_flag']+input_names].values)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Fix mismatch in name between the config file and the expected lume-model format\n",
    "for k in input_variables:\n",
    "    print(input_variables[k])\n",
    "    input_variables[k]['default_value'] = input_variables[k]['default']\n",
    "    del input_variables[k]['default']  \n",
    "\n",
    "input_variables = [ ScalarVariable(**input_variables[k]) for k in input_variables.keys() ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e31d2-c621-46b1-8774-09b64a1a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'/global/homes/e/erod/2024_IFE-superfacility/ml/NN_training/saved_models/GP/{setup}'\n",
    "if setup != 'acave':\n",
    "    output_variables = [\n",
    "        DistributionVariable(name=f\"{name}_{suffix}\", distribution_type=\"MultiVariateNormal\")\n",
    "        for name in output_names\n",
    "        for suffix in [\"sim_task\", \"exp_task\"]\n",
    "    ]\n",
    "else:\n",
    "    output_variables = [\n",
    "        DistributionVariable(name=f\"{name}_{suffix}\", distribution_type=\"MultiVariateNormal\")\n",
    "        for name in output_names\n",
    "        for suffix in [\"sim_task\"]\n",
    "    ]\n",
    "\n",
    "model = GPModel(\n",
    "    model=gp_model, \n",
    "    input_variables=input_variables_ordered,\n",
    "    output_variables=output_variables,\n",
    "    input_transformers=[input_transform],\n",
    "    output_transformers=[output_transform],\n",
    ")\n",
    "\n",
    "model.dump( file=os.path.join(save_path, setup+'GP.yml'),     \n",
    "save_models=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34a115-c193-49af-8520-f662d14d8280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfapi",
   "language": "python",
   "name": "sfapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
