{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e605ff1-df84-4f68-9270-d7ae53e6fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This notebook includes simulation and experimental data\n",
    "## in a database using PyMongo\n",
    "## Author : Revathi Jambunathan\n",
    "## Date : January, 2025\n",
    "\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Neural_Net_Classes import CombinedNN as CombinedNN\n",
    "import torch\n",
    "from botorch.models.transforms.input import AffineInputTransform\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b7df3-7d28-4243-b29e-b6dd0d1447cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select experimental setup for which we are training a model\n",
    "setup = \"ip2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5fa9f-3293-4a4a-9766-11b8642aa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open credential file for database\n",
    "with open(os.path.join(os.getenv('HOME'), 'db.profile')) as f:\n",
    "    db_profile = f.read()\n",
    "\n",
    "# Connect to the MongoDB database with read-only access\n",
    "db = pymongo.MongoClient(\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    username=\"bella_sf_ro\",\n",
    "    password=re.findall('SF_DB_READONLY_PASSWORD=(.+)', db_profile)[0],\n",
    "    authSource=\"bella_sf\")[\"bella_sf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273e573-ea42-4867-9404-d19815b08f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract simulation and experiment data from the database\n",
    "ip2_collection=db[setup]\n",
    "\n",
    "expt_training_set_df = pd.DataFrame( list(ip2_collection.find({\"experiment_flag\":1})) )\n",
    "\n",
    "sim_training_set_df = pd.DataFrame( list(ip2_collection.find({\"experiment_flag\":0})) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c655453-dd37-461b-a8db-2b04b6f984aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of inputs and outputs for this setup\n",
    "with open(\"../../config/variables.yml\") as f:\n",
    "    yaml_dict = yaml.safe_load( f.read() )\n",
    "input_variables = yaml_dict[setup][\"input_variables\"]\n",
    "input_names = [ v['name'] for v in input_variables.values() ] \n",
    "output_variables = yaml_dict[setup][\"output_variables\"]\n",
    "output_names = [ v['name'] for v in output_variables.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6749ef3-c6df-479b-b707-b59584896116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    expt_training_set_df[input_names[0]], \n",
    "    expt_training_set_df[input_names[-1]], \n",
    "    expt_training_set_df[output_names[0]], c='b',alpha=0.3)\n",
    "ax.scatter( \n",
    "    sim_training_set_df[input_names[0]], \n",
    "    sim_training_set_df[input_names[-1]], \n",
    "    sim_training_set_df[output_names[0]], c='g',alpha=0.3)\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b2213-5862-4284-a03f-9885dcd489f0",
   "metadata": {},
   "source": [
    "<h2> Normalize with Affine Input Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791aee40-3f2b-4cbc-b937-ae8abec78185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output normalizations, based on the training set from experiments\n",
    "\n",
    "X = torch.tensor(\n",
    "    expt_training_set_df[ input_names ].values, \n",
    "    dtype=torch.float\n",
    ")\n",
    "input_transform = AffineInputTransform( \n",
    "    len(input_names), \n",
    "    coefficient=X.std(axis=0), \n",
    "    offset=X.mean(axis=0)\n",
    ")\n",
    "\n",
    "y = torch.tensor(\n",
    "    expt_training_set_df[ output_names ].values, \n",
    "    dtype=torch.float\n",
    ").reshape(-1,1)\n",
    "output_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=y.std(axis=0),\n",
    "    offset=y.mean(axis=0)\n",
    ")\n",
    "\n",
    "if (min(X.mean(axis=0)) == 0):\n",
    "    print(\"Mean value used for normalization is 0. This will lead to NaNs \",X.mean(axis=0))\n",
    "if (min(X.std(axis=0)) == 0):\n",
    "    print(\"RMS value used for normalization is 0. This will lead to NaNs \", X.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b755fd-dd03-42d7-843b-00ff3f000cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to the sim training set\n",
    "norm_sim_training_set_df = sim_training_set_df.copy()\n",
    "norm_sim_training_set_df[input_names] = input_transform( torch.tensor( sim_training_set_df[input_names].values ) )\n",
    "norm_sim_training_set_df[output_names] = output_transform( torch.tensor( sim_training_set_df[output_names].values ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22bc58-f108-4824-b526-cf438163dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to the training set from experiments\n",
    "norm_expt_training_set_df = expt_training_set_df.copy()\n",
    "norm_expt_training_set_df[input_names] = input_transform( torch.tensor( expt_training_set_df[input_names].values ) )\n",
    "norm_expt_training_set_df[output_names] = output_transform( torch.tensor( expt_training_set_df[output_names].values ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca4662-2fbf-499e-b5aa-e6515a66e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    norm_expt_training_set_df[input_names[0]], \n",
    "    norm_expt_training_set_df[input_names[-1]], \n",
    "    norm_expt_training_set_df[output_names[0]], c='b',alpha=0.3)\n",
    "ax.scatter( \n",
    "    norm_sim_training_set_df[input_names[0]], \n",
    "    norm_sim_training_set_df[input_names[-1]], \n",
    "    norm_sim_training_set_df[output_names[0]], c='g',alpha=0.3)\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ab553-c692-4f73-bd62-67505cf2c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_expt_inputs_training = torch.tensor( norm_expt_training_set_df[input_names].values, dtype=torch.float)\n",
    "norm_expt_outputs_training = torch.tensor( norm_expt_training_set_df[output_names].values, dtype=torch.float)\n",
    "norm_sim_inputs_training = torch.tensor( norm_sim_training_set_df[input_names].values, dtype=torch.float)\n",
    "norm_sim_outputs_training = torch.tensor( norm_sim_training_set_df[output_names].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf0ee8-b085-4526-b5c9-8edc13181b6b",
   "metadata": {},
   "source": [
    "<h2> Train combined NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c44967-1cb1-480f-801e-f7556135c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_nn = CombinedNN(learning_rate=0.0005)\n",
    "calibrated_nn.train_model(norm_sim_inputs_training, norm_sim_outputs_training,\n",
    "                    norm_expt_inputs_training, norm_expt_outputs_training, num_epochs=40000)\n",
    "\n",
    "calibrated_nn.plot_loss()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaddeb3-8c95-47c2-9674-cda17074a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for training set\n",
    "ax.scatter( \n",
    "    norm_sim_training_set_df[input_names[0]], \n",
    "    norm_sim_training_set_df[input_names[-1]], \n",
    "    norm_sim_training_set_df[output_names[0]], \n",
    "    label='sim training set', alpha=0.7)\n",
    "\n",
    "sim_train_predictions = calibrated_nn.predict_sim(norm_sim_inputs_training)\n",
    "ax.scatter( \n",
    "    norm_sim_training_set_df[input_names[0]], \n",
    "    norm_sim_training_set_df[input_names[-1]],\n",
    "    sim_train_predictions.flatten(), \n",
    "    label='predictions 1', s=50, facecolors='none', edgecolors='r')\n",
    "\n",
    "ax.view_init(elev=40., azim=40)\n",
    "# Set labels and title\n",
    "ax.set_title('Simulation Data v Predictions')\n",
    "ax.set_xlabel(input_names[0])\n",
    "ax.set_ylabel(input_names[-1])\n",
    "ax.set_zlabel(output_names[0])\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608cdcf-a542-4227-80ed-4d9aeed713c1",
   "metadata": {},
   "source": [
    "<h2> Saving the Lume Model - TO do for combined NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30917d-cac4-4f81-b1bb-eef2adaec327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lume_model.models import TorchModel\n",
    "from lume_model.variables import ScalarVariable #, ScalarVariable\n",
    "model = TorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97322355-feb7-4bf3-8fed-355b162f0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=calibrated_nn.sim_to_exp_calibration.weight.clone(), \n",
    "    offset=calibrated_nn.sim_to_exp_calibration.bias.clone() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abc6a2-9b21-4d9e-a95a-2b8e58e05d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = TorchModel(\n",
    "    model=calibrated_nn,\n",
    "    input_variables=[ ScalarVariable(**input_variables[k]) for k in input_variables.keys() ],\n",
    "    output_variables=[ ScalarVariable(**output_variables[k]) for k in output_variables.keys() ],\n",
    "    input_transformers=[input_transform],\n",
    "    output_transformers=[calibration_transform,output_transform] # saving calibration before normalization\n",
    ")\n",
    "\n",
    "model.dump( file='base_simulation_model_with_transformers_new.yml', save_jit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c52d6-29e7-4db5-a76e-9fd56a9efd15",
   "metadata": {},
   "source": [
    "<h2> Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91000638-73a9-41a9-b602-35721e2da113",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.jit.load('base_simulation_model_with_transformers_new_model.jit')\n",
    "loaded_model = loaded_model.to(torch.float)\n",
    "plt.clf()\n",
    "ax = plt.figure().add_subplot()\n",
    "#ax.scatter(norm_sim_training_set_df['z_target_um'], norm_sim_training_set_df['n_protons'], label='Simulation training set')\n",
    "ax.scatter(norm_expt_training_set_df['z_target_um'], norm_expt_training_set_df['n_protons'], label='Expt training set')\n",
    "ax.scatter(norm_expt_test_set_df['z_target_um'], norm_expt_test_set_df['n_protons'], label='Expt test set')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model.calibrate(loaded_model(norm_expt_inputs_training))\n",
    "    numpy_array = output.numpy()\n",
    "ax.scatter(norm_expt_training_set_df['z_target_um'], numpy_array, label=' expt train predictions', s=50, facecolors='none', edgecolors='m')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model.calibrate(loaded_model(norm_expt_inputs_test))\n",
    "    numpy_array = output.numpy()\n",
    "ax.scatter(norm_expt_test_set_df['z_target_um'], numpy_array,label=' expt test predictions', s=50, facecolors='none', edgecolors='r')\n",
    "plt.legend()\n",
    "plt.show()# loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d6c30-d736-45f4-a3d9-8ad5b003f724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c8349-8584-49b9-a2fd-6e0c54ba3414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
