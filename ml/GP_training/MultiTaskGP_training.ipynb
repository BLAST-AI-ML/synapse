{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078802c-94d6-44e1-88d3-34f4b5cc8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pymongo\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import botorch\n",
    "from botorch.models.transforms.input import AffineInputTransform\n",
    "from botorch.models import MultiTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125e381-4dd0-419c-8d69-ac2820011d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select experimental setup for which we are training a model\n",
    "setup = \"ip2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f114c8e-669a-4601-b3d1-5cdfb97ce265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open credential file for database\n",
    "with open(os.path.join(os.getenv('HOME'), 'db.profile')) as f:\n",
    "    db_profile = f.read()\n",
    "\n",
    "# Connect to the MongoDB database with read-only access\n",
    "db = pymongo.MongoClient(\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    username=\"bella_sf_ro\",\n",
    "    password=re.findall('SF_DB_READONLY_PASSWORD=(.+)', db_profile)[0],\n",
    "    authSource=\"bella_sf\")[\"bella_sf\"]\n",
    "\n",
    "# Extract data from the database as pandas dataframe\n",
    "collection = db[setup]\n",
    "df = pd.DataFrame( list(collection.find()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf754b-1fe9-4b84-afae-f53d33304860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of inputs and outputs for this setup\n",
    "with open(\"../../config/variables.yml\") as f:\n",
    "    yaml_dict = yaml.safe_load( f.read() )\n",
    "input_variables = yaml_dict[setup][\"input_variables\"]\n",
    "input_names = [ v['name'] for v in input_variables.values() ] \n",
    "output_variables = yaml_dict[setup][\"output_variables\"]\n",
    "output_names = [ v['name'] for v in output_variables.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c4d2a-2956-4d09-8b22-72edd2c58934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    df[input_names[0]], \n",
    "    df[input_names[-1]], \n",
    "    df[output_names[0]], \n",
    "    c=df.experiment_flag, \n",
    "    alpha=0.3)\n",
    "\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ecbe3-a682-452f-b363-88c993dd1cb5",
   "metadata": {},
   "source": [
    "<h2> Normalize with Affine Input Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71c852-73fe-447a-9768-d34c5b63e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output normalizations\n",
    "\n",
    "X = torch.tensor( df[ input_names ].values, dtype=torch.float )\n",
    "input_transform = AffineInputTransform( \n",
    "    len(input_names), \n",
    "    coefficient=X.std(axis=0), \n",
    "    offset=X.mean(axis=0)\n",
    ")\n",
    "\n",
    "y = torch.tensor( df[ output_names ].values, dtype=torch.float )\n",
    "output_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=y.std(axis=0),\n",
    "    offset=y.mean(axis=0)\n",
    ")\n",
    "\n",
    "if (min(X.mean(axis=0)) == 0):\n",
    "    print(\"Mean value used for normalization is 0. This will lead to NaNs \",X.mean(axis=0))\n",
    "if (min(X.std(axis=0)) == 0):\n",
    "    print(\"RMS value used for normalization is 0. This will lead to NaNs \", X.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2e33b-3bba-45fc-86c1-a6918d13f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to the data set\n",
    "norm_df = df.copy()\n",
    "norm_df[input_names] = input_transform( torch.tensor( df[input_names].values ) )\n",
    "norm_df[output_names] = output_transform( torch.tensor( df[output_names].values ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221842e-b3cf-453d-a2ac-195fe118b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    norm_df[input_names[0]], \n",
    "    norm_df[input_names[-1]], \n",
    "    norm_df[output_names[0]], \n",
    "    c=norm_df.experiment_flag, \n",
    "    alpha=0.3)\n",
    "\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d199d-eaec-4624-9658-90f93e43eab7",
   "metadata": {},
   "source": [
    "# Define a multi-input multi-task GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cef86-310e-4f83-a3f3-c9f70871aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = MultiTaskGP(\n",
    "    torch.tensor( norm_df[['experiment_flag']+input_names].values ),\n",
    "    torch.tensor( norm_df[output_names].values ),\n",
    "    task_feature=0,\n",
    "    covar_module=ScaleKernel(RBFKernel())\n",
    ")\n",
    "    \n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "cov = model.task_covar_module._eval_covar_matrix()\n",
    "print( 'Correlation: ', cov[1,0]/torch.sqrt(cov[0,0]*cov[1,1]).item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55ae96-44f2-4ec4-9900-5c480f3706cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_flag = 0\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for simulation training set\n",
    "ax.scatter( \n",
    "    norm_df[norm_df.experiment_flag==exp_flag][input_names[0]], \n",
    "    norm_df[norm_df.experiment_flag==exp_flag][input_names[-1]], \n",
    "    norm_df[norm_df.experiment_flag==exp_flag][output_names[0]],  \n",
    "    alpha=0.7)\n",
    "\n",
    "# Scatter plot for the predictions\n",
    "predictions = model.posterior(\n",
    "    torch.tensor( norm_df[norm_df.experiment_flag==exp_flag][input_names].values, dtype=torch.float)\n",
    ").mean.detach()\n",
    "\n",
    "ax.scatter( \n",
    "    norm_df[norm_df.experiment_flag==exp_flag][input_names[0]], \n",
    "    norm_df[norm_df.experiment_flag==exp_flag][input_names[-1]],\n",
    "    predictions[:,exp_flag], \n",
    "    label='predictions', s=50, facecolors='none', edgecolors='r')\n",
    "\n",
    "ax.view_init(elev=40., azim=40)\n",
    "# Set labels and title\n",
    "ax.set_xlabel(input_names[0])\n",
    "ax.set_ylabel(input_names[-1])\n",
    "ax.set_zlabel(output_names[0])\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a470c-93b6-428f-ac9d-2d8a3d61c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot data for fixed TOD\n",
    "tod_max = norm_df['TOD_fs3'].max()\n",
    "select = norm_df['TOD_fs3'] > 0.8*tod_max\n",
    "ax.scatter(\n",
    "    norm_df[input_names[-1]][select], \n",
    "    norm_df[output_names[0]][select], \n",
    "    c=norm_df['experiment_flag'][select]\n",
    ")\n",
    "\n",
    "# Plot predictions\n",
    "zmin, zmax = norm_df['z_target_um'].min(), norm_df['z_target_um'].max()\n",
    "z_test_array = torch.tensor (np.linspace(zmin,zmax,100).reshape(-1, 1), dtype=torch.float32) \n",
    "TOD_test_array  = torch.tensor (np.linspace(tod_max,tod_max,100).reshape(-1, 1), dtype=torch.float32) \n",
    "GVD_test_array  = torch.tensor (np.linspace(0.1,0.1,100).reshape(-1, 1), dtype=torch.float32) \n",
    "predictions = model.posterior( torch.cat([ TOD_test_array, GVD_test_array, z_test_array], dim=1) )\n",
    "with torch.no_grad():\n",
    "    m = predictions.mean\n",
    "    l,u = predictions.mvn.confidence_region()\n",
    "\n",
    "exp_flag = 1    \n",
    "plt.plot( z_test_array.numpy(), m[:,exp_flag].detach().numpy() )\n",
    "plt.fill_between( z_test_array.numpy().flatten(), l[:,exp_flag], u[:,exp_flag], alpha = 0.25, lw = 0, color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4856d7-822a-4736-bfe5-1e52515ed095",
   "metadata": {},
   "source": [
    "# Visualize predictions along with confidence interval for the first task (simulation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a06d3-b412-44f1-8b0f-b097f7a5a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "ax.scatter(z_exp, protons_exp, label='Experimental data set', alpha=0.6, color = 'blue')\n",
    "ax.scatter(z_sim, protons_sim, label='Simulation data set', alpha=0.6, color = 'orange')\n",
    "\n",
    "plt.plot(z_test_array.numpy(),predictions.mean[:,0].detach().numpy(), label='Predictions', c='r' )\n",
    "plt.fill_between(z_test_array.numpy().flatten(), lower_bound_sim, upper_bound_sim, color='orange', alpha=0.1, label='Confidence interval for the second task (simulation data)')\n",
    "\n",
    "plt.title(\"Normalized predictions of number of protons\")\n",
    "plt.xlabel('z_target_um')\n",
    "plt.ylabel('n_protons')\n",
    "plt.savefig('./' + 'n_protons_predictions_split_zval__' + '.png')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310ebb6-f641-42a4-a620-54f7c162b27e",
   "metadata": {},
   "source": [
    "# Visualize predictions along with confidence interval for the second task (experimental data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c53e2a-44e3-4b04-909a-147596423d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "ax.scatter(z_exp, protons_exp, label='Experimental data set', alpha=0.6, color = 'blue')\n",
    "ax.scatter(z_sim, protons_sim, label='Simulation data set', alpha=0.6, color = 'orange')\n",
    "\n",
    "plt.plot(z_test_array.numpy(),predictions.mean[:,1].detach().numpy(), label='Predictions', c='r' )\n",
    "plt.fill_between(z_test_array.numpy().flatten(), lower_bound_exp, upper_bound_exp, color='lightblue', alpha=0.25, label='Confidence interval for the second task (experimental data)')\n",
    "\n",
    "plt.title(\"Normalized predictions of number of protons\")\n",
    "plt.xlabel('z_target_um')\n",
    "plt.ylabel('n_protons')\n",
    "plt.savefig('./' + 'n_protons_predictions_split_zval__' + '.png')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63299061-9c38-4c81-8a96-925407457975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03371f-03f3-4659-916a-107226daa650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
