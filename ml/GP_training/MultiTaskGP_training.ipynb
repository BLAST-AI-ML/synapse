{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078802c-94d6-44e1-88d3-34f4b5cc8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pymongo\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import botorch\n",
    "from botorch.models.transforms.input import AffineInputTransform\n",
    "from botorch.models import MultiTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125e381-4dd0-419c-8d69-ac2820011d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select experimental setup for which we are training a model\n",
    "setup = \"ip2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f114c8e-669a-4601-b3d1-5cdfb97ce265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open credential file for database\n",
    "with open(os.path.join(os.getenv('HOME'), 'db.profile')) as f:\n",
    "    db_profile = f.read()\n",
    "\n",
    "# Connect to the MongoDB database with read-only access\n",
    "db = pymongo.MongoClient(\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    username=\"bella_sf_ro\",\n",
    "    password=re.findall('SF_DB_READONLY_PASSWORD=(.+)', db_profile)[0],\n",
    "    authSource=\"bella_sf\")[\"bella_sf\"]\n",
    "\n",
    "# Extract data from the database as pandas dataframe\n",
    "collection = db[setup]\n",
    "df = pd.DataFrame( list(collection.find()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf754b-1fe9-4b84-afae-f53d33304860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of inputs and outputs for this setup\n",
    "with open(\"../../config/variables.yml\") as f:\n",
    "    yaml_dict = yaml.safe_load( f.read() )\n",
    "input_variables = yaml_dict[setup][\"input_variables\"]\n",
    "input_names = [ v['name'] for v in input_variables.values() ] \n",
    "output_variables = yaml_dict[setup][\"output_variables\"]\n",
    "output_names = [ v['name'] for v in output_variables.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c4d2a-2956-4d09-8b22-72edd2c58934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    df[input_names[0]], \n",
    "    df[input_names[-1]], \n",
    "    df[output_names[0]], \n",
    "    c=df.experiment_flag, \n",
    "    alpha=0.3)\n",
    "\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ecbe3-a682-452f-b363-88c993dd1cb5",
   "metadata": {},
   "source": [
    "<h2> Normalize with Affine Input Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71c852-73fe-447a-9768-d34c5b63e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output normalizations\n",
    "\n",
    "X = torch.tensor( df[ input_names ].values, dtype=torch.float )\n",
    "input_transform = AffineInputTransform( \n",
    "    len(input_names), \n",
    "    coefficient=X.std(axis=0), \n",
    "    offset=X.mean(axis=0)\n",
    ")\n",
    "\n",
    "y = torch.tensor( df[ output_names ].values, dtype=torch.float )\n",
    "output_transform = AffineInputTransform( \n",
    "    len(output_names), \n",
    "    coefficient=y.std(axis=0),\n",
    "    offset=y.mean(axis=0)\n",
    ")\n",
    "\n",
    "if (min(X.mean(axis=0)) == 0):\n",
    "    print(\"Mean value used for normalization is 0. This will lead to NaNs \",X.mean(axis=0))\n",
    "if (min(X.std(axis=0)) == 0):\n",
    "    print(\"RMS value used for normalization is 0. This will lead to NaNs \", X.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2e33b-3bba-45fc-86c1-a6918d13f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to the data set\n",
    "norm_df = df.copy()\n",
    "norm_df[input_names] = input_transform( torch.tensor( df[input_names].values ) )\n",
    "norm_df[output_names] = output_transform( torch.tensor( df[output_names].values ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221842e-b3cf-453d-a2ac-195fe118b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dimensional data\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter( \n",
    "    norm_df[input_names[0]], \n",
    "    norm_df[input_names[-1]], \n",
    "    norm_df[output_names[0]], \n",
    "    c=norm_df.experiment_flag, \n",
    "    alpha=0.3)\n",
    "\n",
    "ax.view_init(elev=40., azim=40, roll=0)\n",
    "plt.xlabel(input_names[0])\n",
    "plt.ylabel(input_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d199d-eaec-4624-9658-90f93e43eab7",
   "metadata": {},
   "source": [
    "# Define a multi-input multi-task GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cef86-310e-4f83-a3f3-c9f70871aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = MultiTaskGP(\n",
    "    torch.tensor( norm_df[['experiment_flag']+input_names].values ),\n",
    "    torch.tensor( norm_df[output_names].values ),\n",
    "    task_feature=0,\n",
    ")\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333058dc-616e-4bac-8a87-6e31e259495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sim = torch.tensor(norm_sim_data[['z_target_um']].values)\n",
    "TOD_sim = torch.tensor(norm_sim_data[['TOD_fs3']].values)\n",
    "protons_sim = torch.tensor(norm_sim_data[['n_protons']].values)\n",
    "GVD_sim = torch.tensor(norm_sim_data[['GVD']].values)\n",
    "\n",
    "z_exp = torch.tensor(norm_exp_data[['z_target_um']].values)\n",
    "TOD_exp = torch.tensor(norm_exp_data[['TOD_fs3']].values)\n",
    "protons_exp = torch.tensor(norm_exp_data[['n_protons']].values)\n",
    "GVD_exp = torch.tensor(norm_exp_data[['GVD']].values)\n",
    "\n",
    "sim_tr_list = torch.tensor(norm_sim_data[['z_target_um', 'TOD_fs3', 'GVD']].values)\n",
    "exp_tr_list = torch.tensor(norm_exp_data[['z_target_um', 'TOD_fs3', 'GVD']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c72ecb-1f3b-46f7-b9b5-85b38e29beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "gp_model = multi_input_multi_task_gp(sim_tr_list, protons_sim, exp_tr_list, protons_exp)\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the time taken\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "zmin  = min( np.min(z_sim.numpy()), np.min(z_exp.numpy()))\n",
    "zmax  = max( np.max(z_sim.numpy()), np.max(z_exp.numpy()))\n",
    "print('Simulation data: (zmin,zmin) = (', zmin, ',', zmax, ')')\n",
    "\n",
    "tod_min  = min( np.min(TOD_sim.numpy()), np.min(TOD_exp.numpy()))\n",
    "tod_max  = max( np.max(TOD_sim.numpy()), np.max(TOD_exp.numpy()))\n",
    "print('Simulation data: (tod_min,tod_max) = (', tod_min, ',', tod_max, ')')\n",
    "\n",
    "gvd_min  = min( np.min(GVD_sim.numpy()), np.min(GVD_exp.numpy()))\n",
    "gvd_max  = max( np.max(GVD_sim.numpy()), np.max(GVD_exp.numpy()))\n",
    "print('Simulation data: (gvd_min, gvd_max) = (', gvd_min, ',', gvd_max, ')')\n",
    "\n",
    "z_test_array = torch.tensor (np.linspace(zmin,zmax,100).reshape(-1, 1), dtype=torch.float32) \n",
    "TOD_test_array  = torch.tensor (np.linspace(tod_min,tod_max,100).reshape(-1, 1), dtype=torch.float32) \n",
    "GVD_test_array  = torch.tensor (np.linspace(gvd_min,gvd_max,100).reshape(-1, 1), dtype=torch.float32) \n",
    "\n",
    "predictions_on_train = gp_model.posterior(torch.cat([z_exp, TOD_exp, GVD_exp], dim=1) )\n",
    "\n",
    "predictions = gp_model.posterior( torch.cat([z_test_array, TOD_test_array, GVD_test_array], dim=1) )\n",
    "\n",
    "# Get confidence interval with respect to the task\n",
    "# First column ([:, 0]) represents the lower bound of the 95% confidence interval for the first task (e.g., simulated data).\n",
    "# Second column ([:, 1])represents the lower bound of the 95% confidence interval for the second task (e.g., experimental data).\n",
    "lower_bound_sim = predictions.confidence_region()[0].detach().numpy()[:,0]\n",
    "upper_bound_sim = predictions.confidence_region()[1].detach().numpy()[:,0]\n",
    "\n",
    "lower_bound_exp = predictions.confidence_region()[0].detach().numpy()[:,1]\n",
    "upper_bound_exp = predictions.confidence_region()[1].detach().numpy()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a470c-93b6-428f-ac9d-2d8a3d61c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "ax.scatter(z_exp, protons_exp, label='Experimental data test', alpha=0.6, color = 'blue')\n",
    "plt.legend()\n",
    "for fixed_tod_val in [tod_max]:#np.linspace(0,tod_max, 3):\n",
    "    for fixed_gvd_val in [0.1]:#np.linspace(0,0,3):\n",
    "        TOD_test_array  = torch.tensor (np.linspace(fixed_tod_val,fixed_tod_val,100).reshape(-1, 1), dtype=torch.float32) \n",
    "        GVD_test_array  = torch.tensor (np.linspace(fixed_gvd_val,fixed_gvd_val,100).reshape(-1, 1), dtype=torch.float32) \n",
    "\n",
    "        predictions = gp_model.posterior( torch.cat([z_test_array, TOD_test_array, GVD_test_array], dim=1) )\n",
    "        \n",
    "        plt.plot(z_test_array.numpy(),predictions.mean[:,1].detach().numpy(),  c='r', label = 'Predictions: TOD='+ str(np.round(fixed_tod_val,2)) +', GVD='+ str(np.round(fixed_gvd_val,2)) )\n",
    "        plt.xlabel('Normalized z_target')\n",
    "        plt.ylabel('Normalized number of protons')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4856d7-822a-4736-bfe5-1e52515ed095",
   "metadata": {},
   "source": [
    "# Visualize predictions along with confidence interval for the first task (simulation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a06d3-b412-44f1-8b0f-b097f7a5a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "ax.scatter(z_exp, protons_exp, label='Experimental data set', alpha=0.6, color = 'blue')\n",
    "ax.scatter(z_sim, protons_sim, label='Simulation data set', alpha=0.6, color = 'orange')\n",
    "\n",
    "plt.plot(z_test_array.numpy(),predictions.mean[:,0].detach().numpy(), label='Predictions', c='r' )\n",
    "plt.fill_between(z_test_array.numpy().flatten(), lower_bound_sim, upper_bound_sim, color='orange', alpha=0.1, label='Confidence interval for the second task (simulation data)')\n",
    "\n",
    "plt.title(\"Normalized predictions of number of protons\")\n",
    "plt.xlabel('z_target_um')\n",
    "plt.ylabel('n_protons')\n",
    "plt.savefig('./' + 'n_protons_predictions_split_zval__' + '.png')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310ebb6-f641-42a4-a620-54f7c162b27e",
   "metadata": {},
   "source": [
    "# Visualize predictions along with confidence interval for the second task (experimental data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c53e2a-44e3-4b04-909a-147596423d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "ax.scatter(z_exp, protons_exp, label='Experimental data set', alpha=0.6, color = 'blue')\n",
    "ax.scatter(z_sim, protons_sim, label='Simulation data set', alpha=0.6, color = 'orange')\n",
    "\n",
    "plt.plot(z_test_array.numpy(),predictions.mean[:,1].detach().numpy(), label='Predictions', c='r' )\n",
    "plt.fill_between(z_test_array.numpy().flatten(), lower_bound_exp, upper_bound_exp, color='lightblue', alpha=0.25, label='Confidence interval for the second task (experimental data)')\n",
    "\n",
    "plt.title(\"Normalized predictions of number of protons\")\n",
    "plt.xlabel('z_target_um')\n",
    "plt.ylabel('n_protons')\n",
    "plt.savefig('./' + 'n_protons_predictions_split_zval__' + '.png')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63299061-9c38-4c81-8a96-925407457975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03371f-03f3-4659-916a-107226daa650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
